{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Робо-журналистика. Мини-проект\n",
    "\n",
    "## Программа для подбора изображений к тексту\n",
    "\n",
    "Пользователь загружает англоязычный текст и получает файл с ключевыми словами и ссылками на 30 (макисмум) изображений к тексту с сервиса Flickr, которые можно использовать в коммерческих целях без указания авторства (No known copyright restrictions, Public Domain Dedication (CC0), Public Domain Mark). В файле содержится также название изображения и 2 ссылки на него: большой и средний размер.\n",
    "\n",
    "### Алгоритм\n",
    "\n",
    "1. Программа принимает на вход файл с англоязычным текстом в формате txt\n",
    "2. Обработка текста\n",
    "    + Все слова с маленькой буквы, без знаков препинания\n",
    "    + Подсчитывается частота каждого слова (Counter)\n",
    "    + Поиск стоп-слов в тексте (файл \"stop-list.txt\") и присвоение стоп-словам частоты равной 0\n",
    "    + Выделение 5 ключевых слов текста\n",
    "3. Запрос к API Flickr (задается список тегов, поиск изображений со свободной лицензией)\n",
    "4. Выбор необходимых данных: title, farm, id, server, secret\n",
    "5. Формирование ссылок на фото\n",
    "6. Запись необходимых данных в файл \"links_to_images.txt\": ключевые слова, порядковый номер, название фото, ссылки\n",
    "\n",
    "<b><i>Андрей Нестеров, МДЖ172</i></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from collections import Counter\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import Image, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_photo_for_article(text):\n",
    "    \"\"\"\n",
    "    Функция принимает на вход файл с текстом и возвращает файл \"links_to_images.txt\"\n",
    "    с ключевыми словами текста и ссылками на 30 (максимум) изображений из сервиса Flickr к тексту.\n",
    "    Изображения не защищены копирайтом и могут использоваться без указания авторства в коммерческих целях.\n",
    "    \"\"\"\n",
    "    \n",
    "    list_of_words = [] # Список для всех слов из загруженного файла\n",
    "    list_of_stop_words = [] # Список для слов из стоп-листа\n",
    "    list_of_keywords = [] # Список для ключевых слов\n",
    "    dict_of_urls = {} # Словарь для хранения ссылок в виде {'id': ('название фото', 'ссылки')}\n",
    "    list_of_data = [] # Список для хранения строк, который будет записан в файл links_to_images.txt\n",
    "    preview_links = [] # Список для ссылок на превью \n",
    "    \n",
    "    with open(text) as file:\n",
    "        original = file.read()\n",
    "        \n",
    "    for lines in original.strip().split(): # Делим весь текст на слова и добавляем их в список\n",
    "        lines_no_punct = lines.lower().rstrip(\".\").rstrip(\",\").rstrip(\")\").lstrip(\"(\") # С маленькой буквы без знаков препинания\n",
    "        list_of_words.append(lines_no_punct)\n",
    "\n",
    "    with open(\"stop-list.txt\") as stop_list: # Открываем файл \"стоп-лист\"\n",
    "        stop_list_original = stop_list.read()\n",
    "\n",
    "    for elements in stop_list_original.split(): # Добавляем все слова из стоп-листа в список\n",
    "        list_of_stop_words.append(elements)\n",
    "    \n",
    "    cntr = Counter(list_of_words) # Частота слова в тексте \n",
    "    statistic = dict(cntr) # Превращаем counter в словарь\n",
    "\n",
    "    for words in list_of_stop_words: # Ищем стоп-слова в тексте\n",
    "        if words in statistic: # Если слово встречается, то\n",
    "            statistic[words] = 0 # Приравниваем его частоту к 0\n",
    "\n",
    "    keys = Counter(statistic).most_common(5) # Выводим топ-5 самых частых слов (ключевые слова)\n",
    "\n",
    "    for element in keys: # Добавляем ключевые слова в список \n",
    "        list_of_keywords.append(element[0])\n",
    "        \n",
    "    # Превращаем список в строку формата \"keyword, keyword\"\n",
    "    \n",
    "    keywords = f\"{list_of_keywords[0]}, {list_of_keywords[1]}, {list_of_keywords[2]}, {list_of_keywords[3]}, {list_of_keywords[4]}\"\n",
    "    \n",
    "    # Получаем нужные фото по тегам, запрос в формате XML\n",
    "    url = \"https://api.flickr.com/services/rest/?\"\n",
    "    query = {'api_key':'c949a8a9e9e36da8cfceb75a95ff7980',\n",
    "             'method': 'flickr.photos.search',\n",
    "             'content_type':'1', # Ищем только фото\n",
    "             'tags': keywords, # Задаем список тэгов (ключевых слов)\n",
    "             'tag_mode': 'any', # Любое соответсвие тэгу\n",
    "             'per_page':'30', # Максимум 30 фото\n",
    "             'page':'1', # На первой странице\n",
    "             'sort':'interestingness-desc', # Сортирвка - по \"интересности\"\n",
    "             'license':'7,9,10' # Фото без копирайта\n",
    "            }\n",
    "\n",
    "    f = requests.get(url, params=query)\n",
    "    page = BeautifulSoup(f.text, \"lxml\")\n",
    "    for photo in page.html.body.photos('photo'):\n",
    "        photo_id = f\"{photo['id']}\"\n",
    "        photo_title = f\"{photo['title']}\"\n",
    "        url_string_large = f\"Large - https://farm{photo['farm']}.staticflickr.com/{photo['server']}/{photo['id']}_{photo['secret']}_b.jpg\"\n",
    "        url_string_medium = f\"Medium - https://farm{photo['farm']}.staticflickr.com/{photo['server']}/{photo['id']}_{photo['secret']}_z.jpg\"\n",
    "        dict_of_urls[photo_id] = photo_title, url_string_large, url_string_medium\n",
    "        url_string_preview = f\"https://farm{photo['farm']}.staticflickr.com/{photo['server']}/{photo['id']}_{photo['secret']}_m.jpg\"\n",
    "        preview_links.append(url_string_preview)\n",
    "\n",
    "    for key, value in dict_of_urls.items():\n",
    "        string_data = f\"'{dict_of_urls[key][0]}', {dict_of_urls[key][1]}, {dict_of_urls[key][2]}\"\n",
    "        list_of_data.append(string_data)\n",
    "\n",
    "    links = open(\"links_to_images.txt\", \"w\") # Подготавливаем файл, который содержит\n",
    "    print(f\"Keywords: {keywords}\", file=links) # Ключевые слова\n",
    "    for i, elements in enumerate(list_of_data): \n",
    "        index = i + 1\n",
    "        print(index, elements, file=links) # Порядковый номер, название фото, ссылки\n",
    "    links.close()\n",
    "    \n",
    "    print(\"Your images are ready! Have a look at some of them.\\nPlease, open 'links_to_images.txt' in your directory to get all the links.\")\n",
    "    \n",
    "    for link in preview_links[0:5]: # Показываем 5 превью\n",
    "        display(Image(link))\n",
    "        \n",
    "    return\n",
    "    #return (\"Ready! Open file 'links_to_images.txt' in your directory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_photo_for_article(\"journ.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
